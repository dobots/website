<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Distributed Organisms B.V., shorthand DoBots, specializes in Smart Robots and Smart Buildings. DoBots implements localization, mapping, and navigation algorithms on robots and indoor localization, automation, and tracking algorithms in buildings.">
<meta name="author" content="Distributed Organisms B.V.">
<link rel="icon" type="image/x-icon" href="/images/favicon.ico?">
<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png">


<title>DoBots | Extreme Learning Machines</title>




<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

<link rel="stylesheet" type="text/css" href="/assets/elusive-webfont-b4b08c54aa385fbc9433a5864604eb0a37430d49016644f6c2225b9c9f6528d4.css">

<!-- Custom styles for this template -->

<link rel="stylesheet" type="text/css" href="/assets/flexslider-af37d743866caa19c33f16fdb8585f2b6331c7b25bfcb9b0b2fd4720d61df9b5.css">
<link rel="stylesheet" type="text/css" href="/assets/dobots-style-6a93bbafd311befa179f35a7f457349cb1b7ed24686877defdb4530f84dcc1fe.css">

<!--[if lt IE 9]>
	<script src="/assets/themes//resources/respond/Respond.min.js"></script>
<![endif]-->

<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
<link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">


</head>

<body>
    <!--
<div id="headerBar" onclick="location.href='http://crownstone.rocks';">
<center>
<h4>
<a href="http://crownstone.rocks/">http://crownstone.rocks</a> power outlet!
</h4>
</center>
</div>
    -->
<header id="header" class="mini-wrap">
	<div class="navbar navbar-inverse" role="navigation">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="/"><img src="/images/logo.png" class="img-responsive" alt="DoBots"></a>
			</div>

			<div class="collapse navbar-collapse">
				<ul class="nav navbar-nav navbar-right main-nav">
					
					
					


  
    
      
    
  
    
      
      	
      	<li><a href="/applications/cleaning/">Applications</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/products/autopilot/">Technology</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/jobs/">Jobs</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/blog/">Blog</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/about-us/">About</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/search/">Search</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
	<li><a href="mailto:info@dobots.nl?subject=Get%20in%20contact">Contact</a></li>




				</ul>
			</div>
		</div>
	</div>
</header>

<section id="sub-menu" class="mini-wrap">
	<div class="container">
		<div class="row">
			<div class="col-md-12">
				<ul class="list-unstyled sub-menu pull-left slogan">
					<!--					<li>"Computers, come, join us in the real world!"</li> -->
					<li>
<a href="/2014/05/23/best-european-startup/">Best European Startup Award</a> winner of <a href="http://robotlaunch.com/">Robot Launch</a>!
					</li>
				</ul>
                <!--
				<ul class="list-unstyled sub-menu pull-right">
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
					
						
						
							
							
							
							
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
						
					
				</ul>
                -->
			</div>
		</div>
	</div>
</section> <!--end / sub-menu-->


<!--
<div class="page-header">
  <h1>Extreme Learning Machines </h1>
</div>
-->

<div class="container">
	<div class="row post-full">
		<div class="col-md-12">
			<div class="date">
				<strong class="date_month">Apr</strong>
				<strong class="date_day">19</strong>
				<strong class="date_year">2013</strong>
				<!--      <span>19 April 2013</span> -->
			</div>
			
			
			<div class="author-block">
				
				<span class="author">Laurens Bliek</span>
			</div>
			
			<div class="post">
				<div class="content">
					
<h1 id="extreme-learning-machines">Extreme Learning Machines</h1>

<p><a href="https://en.wikipedia.org/wiki/Neural_network">Artificial neural networks</a> are
a common technique in the field of machine learning. Inspired by biology, they
are used in, among others, function approximation, time series prediction,
classification and pattern recognition. There exist many variations in the
type of network, the types of neurons used, and in the learning algorithms.
The most common learning algorithm for a feedforward neural network is
<a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>.</p>

<p>Although the backpropagation algorithm is a very popular learning algorithm,
there are some drawbacks:</p>

<ul>
  <li>A small learning rate can lead to slow convergence.</li>
  <li>A large learning rate can lead to divergence.</li>
  <li>The algorithm might get stuck at local minima.</li>
  <li>It is possible to overtrain the network, reducing the generalisation performance.</li>
  <li>The algorithm can be very time-consuming, especially for large networks.</li>
</ul>

<p>In 2004, a new alternative to backpropagation for learning feedforward neural
networks has been proposed by Huang: Extreme Learning Machine (ELM). This
algorithm is easy to implement and does not suffer from the drawbacks above. I
will first show a summary of the theory behind this algorithm, and then
provide a supervised learning example implemented in MATLAB.</p>

<p>Note that this technique is very similar to Reservoir Computing techniques for
recurrent neural networks. See <a href="/2012/07/06/echo-state-networks/">Remco’s blog about Echo State Networks</a> for a description.</p>

<h2 id="theory">Theory</h2>

<p>Suppose we want to train a feedforward neural network with one hidden layer in
a supervised learning setting by providing input <script type="math/tex">x</script> and desired output <script type="math/tex">y</script>.
If the hidden layer contains synaptic weights <script type="math/tex">SH</script> and bias <script type="math/tex">BH</script> and the
hyperbolic tangent as a sigmoid activation function, the output <script type="math/tex">H</script> of the
hidden layer can be computed as <script type="math/tex">H = tanh(-BH + SH*x)</script>.</p>

<p>For the output layer, we use a linear activation function (though we could
also use a sigmoid function here) and weights <script type="math/tex">S</script> and no bias. Then the output
<script type="math/tex">O</script> of the whole neural network can be computed as <script type="math/tex">O = S*H</script>.</p>

<p>Now we want the neural network to produce an output <script type="math/tex">O</script> that minimizes the
error <script type="math/tex">||y-O||</script>, given input data <script type="math/tex">x</script>. In the backpropagation algorithm this
is done by performing a gradient descent on the error to update the hidden
weights <script type="math/tex">S*H</script> and the output weights <script type="math/tex">S</script>. In the ELM approach, however, the
hidden weights are initialised randomly and remain fixed; only the output
weights are adapted.</p>

<p>Suppose the weights and biases of the hidden layer are fixed, then we can
compute the outputs of the hidden layer for all the training samples at once.
This gives a matrix <script type="math/tex">\bf{H}</script> of dimension <script type="math/tex">h*T</script>, where <script type="math/tex">h</script> is the amount of
hidden neurons and <script type="math/tex">T</script> the amount of training samples. Since the desired
output <script type="math/tex">y</script> is also known for all the training samples, for the network to
produce the desired output we need to solve the linear matrix equation <script type="math/tex">S*\bf{H} = y</script>. This equation does not necessarily have an exact solution, but the best (smallest norm least-squares) solution of this equation is <script type="math/tex">S = y*\bf{H^+}</script>, where <script type="math/tex">\bf{H^+}</script> is the <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_pseudoinverse">Moore-Penrose pseudo-inverse</a> of <script type="math/tex">\bf{H}</script>. Even with fixed weights going from input to hidden layer, using this <script type="math/tex">S</script> for the output weights gives good results in theory and in practice.
For more information, see <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.217.3692&amp;rep=rep1&amp;type=pdf">Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. “Extreme learning machine: theory and applications.” Neurocomputing 70.1 (2006): 489-501</a>.</p>

<h2 id="practice">Practice</h2>

<p>The above approach is easy to implement in MATLAB, or in any environment that
can handle a pseudo-inverse (or you can implement a pseudo-inverse yourself).
Here, an example is shown to let a feedforward neural network with one hidden
layer learn the XOR function.</p>

<p>First, set the amount of training and generalisation samples and the input and
output dimensions:</p>

<pre><code>T = 100; %amount of
training samples gen = round(0.2*T); %amount of generalisation samples id = 2;
%input dimension od = 1; %output dimension 
</code></pre>

<p>For the input, random values from the set <script type="math/tex">\{0,1\}^2</script> are picked. And since the
function we want to learn is actually a known function, we can easily compute
the desired output values:</p>

<pre><code>x = round(rand(id,T+gen));
%input data y = zeros(od,T+gen); %output data for t=1:T+gen y(:,t) =
xor(x(1,t),x(2,t)); %function to be learned end 
</code></pre>

<p>Of course, in a more realistic application <script type="math/tex">y</script> might not be given as a
function of <script type="math/tex">x</script> so easily, since that is exactly what the neural network needs
to learn. But in this example the function to be learned is known explicitly.
We also know the different possible values of the input data, so only 4 hidden
nodes will suffice for the network. In practice, one might need to find the
amount of hidden nodes just by trial and error or by using an incremental
algorithm.</p>

<p>Initialise the neural network:</p>

<pre><code>h = 4; %amount of hidden nodes
SH = rand(h,id); %input-to-hidden synaptic weights, fixed
BH = rand(h,1)*ones(1,T+gen); %hidden layer bias, fixed
S = zeros(od,h); %hidden-to-output synaptic weights, to be adapted 
</code></pre>

<p>The hidden layer bias and weights will be fixed during the whole algorithm,
while the output weights will be adapted. It is important that the randomly
initialised weights and biases are drawn from a continuous probability
distribution, but it does not matter which one.</p>

<p>The outputs of the hidden layer can be computed for every training sample:</p>

<pre><code>H = tanh(-BH + SH*x); %Calculate hidden layer output matrix
</code></pre>

<p>When using your own inputs and outputs, sometimes the outputs of the hidden
layer will all be 1 or -1, or close to it. This could give problems in the
learning phase. You can try to normalise the input or the weights and biases
in this case.</p>

<p>The learning phase is now only one line of code:</p>

<pre><code>S = y(:,1:T)*pinv(H(:,1:T)); %adjust hidden-to-output synaptic weights during learning phase
</code></pre>

<p>Only the output weights are adapted, the hidden weights remain fixed. The
neural network has now learned the XOR function in one step, by only adapting
the output weights. The next code can be used to visualise this:</p>

<pre><code>O = S*H; %output
plot(y,'b*'); %desired output hold on;
plot(1:T,O(:,1:T),'r.'); %output during learning phase
hold on; plot(T+1:T+gen,O(:,T+1:T+gen),'g.'); %output during generalisation phase
hold off;
</code></pre>

<p><img src="/attachments/extreme_learning_machines.png" alt="Extreme learning machines" title="Extreme learning machines"></p>

				</div>

				

				
				<hr>

				<div class="social-button-footer">
					<p>
					<a class="btn btn-social-icon btn-twitter" href="http://twitter.com/intent/tweet?url=https://dobots.nl/2013/04/19/extreme-learning-machines&amp;text=Extreme%20Learning%20Machines"><i class="icon-twitter"></i></a>
					<a class="btn btn-social-icon btn-facebook" href="http://facebook.com/sharer.php?u=https://dobots.nl/2013/04/19/extreme-learning-machines"><i class="icon-facebook"></i></a>
					<a class="btn btn-social-icon btn-googleplus" href="https://plus.google.com/share?url=https://dobots.nl/2013/04/19/extreme-learning-machines"><i class="icon-googleplus"></i></a>
					<a class="btn btn-social-icon btn-linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://dobots.nl/2013/04/19/extreme-learning-machines"><i class="icon-linkedin"></i></a>
					<a class="btn btn-social-icon btn-reddit" href="http://reddit.com/submit?url=https://dobots.nl/2013/04/19/extreme-learning-machines&amp;title=Extreme%20Learning%20Machines"><i class="icon-reddit"></i></a>
					</p>
				</div>


				<ul class="pagination">
					
					<li class="prev"><a href="/2013/04/12/visualizing-accelerometer-data" title="Visualizing accelerometer data">← Previous</a></li>
					
					<li><a href="/blog">Archive</a></li>
					
					<li class="next"><a href="/2013/04/26/robot-remote-control-with-%C3%B8mq" title="Robot Remote Control with ØMQ">Next →</a></li>
					
				</ul>
				<hr>
				


  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'dobots'; 
    
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="https://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




			</div>
		</div>
	</div>



<footer id="footer" class="mini-wrap gray">
	<div class="container">
		<div class="row">
			<div class="col-xs-6 col-sm-6 col-md-6 more-padding">
				<img src="/images/youtube.png" alt="youtube"> Watch our <a href="https://www.youtube.com/channel/UC7bsuzp2BfL5F5RX07oLIzw">movies</a> and follow us on <a href="http://facebook.com/dobots">Facebook!</a>
</div>
			<div class="col-xs-6 col-sm-6 col-md-6">
				<ul class="list-items pull-right gutter-top-btm">
					<li><a href="index.html">
						<img src="/images/footer-logo.png" class="img-responsive" alt="DoBots"></a></li>
					<li class="robot-info-dilog">
<a href="#">
						<img src="/images/two-robot.png" width="103" height="85" alt="robot">
					</a>
					<div class="footer-robot-dilog">
						<div class="inner-robot-dilog">
							Do you have a question? <script type="text/javascript">/*<![CDATA[*/var a=new Array(".nl","bots","do","@","fo","in");document.write("<a href='mailto:");for(i=a.length-1;i>=0;i--){document.write(a[i])}document.write("?subject=DoBots Contact' class='btn btn-default'>Yes</a>");/*]]>*/</script>
							<div class="inner-arrow-right">
								<img alt="dilog" class="img-responsive" src="/images/inner-dilog.png" draggable="false"> </div>
						</div>

					</div>
					</li>
				</ul>

			</div>
		</div>
	</div>
</footer>




  <script type="text/javascript">
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-17146802-10', 'auto');
ga('send', 'pageview');
</script>
<script type="text/javascript" async src="https://www.google-analytics.com/analytics.js"></script>






<!-- in debug mode, Google Chrome worries about .map files, do not worry -->


<script type="text/javascript" src="/assets/jquery.min-7f30f220312176c728c3bb41a567ccc2e1ce2e7a8dd7c9cefd59fe197ba047b2.js"></script>

<!-- Latest compiled and minified JavaScript -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script type="text/javascript" src="/assets/jquery.flexslider-122776e067a7b77f685ce8fbbd3cb75136ce8ca23f243a50de28c1545ec6bb68.js"></script>

<script type="text/javascript" async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/javascript">
$(window).load(function(){
		$('.text-slider').flexslider({
			animation: "slide",
			start: function(slider){
				$('body').removeClass('loading');
			}
		});
	});
</script>

</div>
</body>
</html>
