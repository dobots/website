<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Distributed Organisms B.V., shorthand DoBots, specializes in Smart Robots and Smart Buildings. DoBots implements localization, mapping, and navigation algorithms on robots and indoor localization, automation, and tracking algorithms in buildings.">
<meta name="author" content="Distributed Organisms B.V.">
<link rel="icon" type="image/x-icon" href="/images/favicon.ico?">
<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png">


<title>DoBots | Self-learning robots</title>




<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

<link rel="stylesheet" type="text/css" href="/assets/elusive-webfont-b4b08c54aa385fbc9433a5864604eb0a37430d49016644f6c2225b9c9f6528d4.css">

<!-- Custom styles for this template -->

<link rel="stylesheet" type="text/css" href="/assets/flexslider-af37d743866caa19c33f16fdb8585f2b6331c7b25bfcb9b0b2fd4720d61df9b5.css">
<link rel="stylesheet" type="text/css" href="/assets/dobots-style-6a93bbafd311befa179f35a7f457349cb1b7ed24686877defdb4530f84dcc1fe.css">

<!--[if lt IE 9]>
	<script src="/assets/themes//resources/respond/Respond.min.js"></script>
<![endif]-->

<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
<link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">


</head>

<body>
    <!--
<div id="headerBar" onclick="location.href='http://crownstone.rocks';">
<center>
<h4>
<a href="http://crownstone.rocks/">http://crownstone.rocks</a> power outlet!
</h4>
</center>
</div>
    -->
<header id="header" class="mini-wrap">
	<div class="navbar navbar-inverse" role="navigation">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="/"><img src="/images/logo.png" class="img-responsive" alt="DoBots"></a>
			</div>

			<div class="collapse navbar-collapse">
				<ul class="nav navbar-nav navbar-right main-nav">
					
					
					


  
    
      
    
  
    
      
      	
      	<li><a href="/applications/cleaning/">Applications</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/products/autopilot/">Technology</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/jobs/">Jobs</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/blog/">Blog</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/about-us/">About</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/search/">Search</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
	<li><a href="mailto:info@dobots.nl?subject=Get%20in%20contact">Contact</a></li>




				</ul>
			</div>
		</div>
	</div>
</header>

<section id="sub-menu" class="mini-wrap">
	<div class="container">
		<div class="row">
			<div class="col-md-12">
				<ul class="list-unstyled sub-menu pull-left slogan">
					<!--					<li>"Computers, come, join us in the real world!"</li> -->
					<li>
<a href="/2014/05/23/best-european-startup/">Best European Startup Award</a> winner of <a href="http://robotlaunch.com/">Robot Launch</a>!
					</li>
				</ul>
                <!--
				<ul class="list-unstyled sub-menu pull-right">
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
						
					
					
						
						
							
							
							
							
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
								
							
						
					
				</ul>
                -->
			</div>
		</div>
	</div>
</section> <!--end / sub-menu-->


<!--
<div class="page-header">
  <h1>Self-learning robots </h1>
</div>
-->

<div class="container">
	<div class="row post-full">
		<div class="col-md-12">
			<div class="date">
				<strong class="date_month">Jul</strong>
				<strong class="date_day">26</strong>
				<strong class="date_year">2013</strong>
				<!--      <span>26 July 2013</span> -->
			</div>
			
			
			<div class="author-block">
				
				<span class="author">Laurens Bliek</span>
			</div>
			
			<div class="post">
				<div class="content">
					
<h1 id="self-learning-robots">Self-learning robots</h1>

<p>Autonomous robots are supposed to perform their tasks without human guidance.
One way to make this happen is by implementing some reward or penalty inside
the robot; something similar to pleasure and pain in humans and animals. If
the robot performs its task correctly, it receives a reward, if not, it
receives a penalty, and the robot will choose its actions in such a way that
it maximises its reward. This is studied in the area of <a href="http://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.</p>

<p>Suppose an autonomous robot ‘wakes up’ in an unknown body and in an unknown
environment, and its task is to understand itself and the environment. This
is, of course, a huge task that can even take some of us humans a lifetime to
learn, so we will start with a simple version of this task: the robot has to
predict what it will perceive when it performs a simple action, like moving
one step forward. If it can succesfully do this in every possible situation
and for every possible action, we could say that the robot has some sort of
understanding of itself and the environment.</p>

<p>Now the problem of the creators of the robot is to implement a reward that
will cause the robot to predict correctly in every possible situation. This
can be divided in two goals: predict correctly, and explore new situations.
This is similar to the exploration vs. exploitation trade-off in reinforcement
learning, but a big difference is that we cannot say that moving towards a
specific location in the environment for example, should give a high reward,
since the environment is unknown. The only available information is the action
<script type="math/tex">a</script> of the robot, and what the robot perceives: sensory data <script type="math/tex">s</script>.</p>

<p>Let’s say that every timestep <script type="math/tex">t</script> the robot can predict sensory data <script type="math/tex">s_{t+1}</script> by
using current action <script type="math/tex">a_t</script> and current sensory data <script type="math/tex">s_t</script> and a predictor
<script type="math/tex">P(s_t,a_t)</script>. The predictor can ‘learn’ by using any machine learning algorithm,
for example by training a neural network. In general the predictor will not be
perfect, so we define a prediction error <script type="math/tex">e_t=|s_{t+1}-P(s_t,a_t)|</script>. This error
can be used to let the robot achieve its two goals of predicting correctly and
explore new situations.</p>

<h2 id="minimise-prediction-error">Minimise prediction error</h2>

<p>If the robot receives a reward for minimising the prediction error, the
expected behaviour is that the robot will choose those actions that are
easiest to predict, like standing still, to receive rewards easily. This makes
it achieve one goal, namely to predict correctly, but it will not cause the
robot to explore new situations.</p>

<h2 id="maximise-prediction-error">Maximise prediction error</h2>

<p>If the robot receives a reward for high prediction errors, this will generally
lead to explorative behaviour. The robot will move towards situations where it
expects to have a high error, thus receiving rewards. This should work if the
predictor can learn all of these situations, but in general it takes some time
for a predictor to learn something. Moreover, there might be situations where
the predictor cannot really learn to predict, like the noise on a television
screen or if the robot moves too fast. Then the robot will move towards these
situations and stay there because it will keep getting a high reward for this.</p>

<h2 id="maximise-learning-progress">Maximise learning progress</h2>

<p>A better solution is to give the robot a reward when it <em>decreases</em> the
prediction error. A decrease in error is also called ‘learning progress’. When
it maximises this learning progress, the robot might start simple by just
standing still. At first, the prediction error will be high because it is the
first time ever that the robot stands still. But it is not difficult to
predict what the robot will perceive in this situation, so the prediction
error will decrease. At some point, the error cannot decrease anymore (for
example, because it might be zero), so then the robot has learned the
situation and will move on to reach a situation where the error can still
decrease. This solves both the ‘predicting correctly’ part and the ‘explore
new situations’ part. If the robot ever encounters a situation where it cannot
learn to predict correctly, then the error will not decrease and the robot
will also move to a different situation.</p>

<p>Although there are still some drawbacks even to this last method, it is a good
method to let the robot predict correctly and also explore new situations. For
further reading, see:</p>

<ol>
  <li>Oudeyer, Pierre-Yves, and Frederic Kaplan. “What is intrinsic motivation? a typology of computational approaches.” <em>Frontiers in neurorobotics</em> 1 (2007).</li>
  <li>Oudeyer, Pierre-Yves, et al. “The playground experiment: Task-independent development of a curious robot.” <em>Proceedings of the AAAI Spring Symposium on Developmental Robotics</em>. Stanford, California, 2005.</li>
  <li>Schmidhuber, Jürgen. “Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts.” <em>Connection Science</em> 18.2 (2006): 173-187.</li>
</ol>


				</div>

				

				
				<hr>

				<div class="social-button-footer">
					<p>
					<a class="btn btn-social-icon btn-twitter" href="http://twitter.com/intent/tweet?url=https://dobots.nl/2013/07/26/self-learning-robots&amp;text=Self-learning%20robots"><i class="icon-twitter"></i></a>
					<a class="btn btn-social-icon btn-facebook" href="http://facebook.com/sharer.php?u=https://dobots.nl/2013/07/26/self-learning-robots"><i class="icon-facebook"></i></a>
					<a class="btn btn-social-icon btn-googleplus" href="https://plus.google.com/share?url=https://dobots.nl/2013/07/26/self-learning-robots"><i class="icon-googleplus"></i></a>
					<a class="btn btn-social-icon btn-linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://dobots.nl/2013/07/26/self-learning-robots"><i class="icon-linkedin"></i></a>
					<a class="btn btn-social-icon btn-reddit" href="http://reddit.com/submit?url=https://dobots.nl/2013/07/26/self-learning-robots&amp;title=Self-learning%20robots"><i class="icon-reddit"></i></a>
					</p>
				</div>


				<ul class="pagination">
					
					<li class="prev"><a href="/2013/07/19/irc-xmpp-and-whatsapp" title="IRC, XMPP and WhatsApp">← Previous</a></li>
					
					<li><a href="/blog">Archive</a></li>
					
					<li class="next"><a href="/2013/10/01/replicator-robots-final" title="Replicator Robots Final">Next →</a></li>
					
				</ul>
				<hr>
				


  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'dobots'; 
    
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="https://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




			</div>
		</div>
	</div>



<footer id="footer" class="mini-wrap gray">
	<div class="container">
		<div class="row">
			<div class="col-xs-6 col-sm-6 col-md-6 more-padding">
				<img src="/images/youtube.png" alt="youtube"> Watch our <a href="https://www.youtube.com/channel/UC7bsuzp2BfL5F5RX07oLIzw">movies</a> and follow us on <a href="http://facebook.com/dobots">Facebook!</a>
</div>
			<div class="col-xs-6 col-sm-6 col-md-6">
				<ul class="list-items pull-right gutter-top-btm">
					<li><a href="index.html">
						<img src="/images/footer-logo.png" class="img-responsive" alt="DoBots"></a></li>
					<li class="robot-info-dilog">
<a href="#">
						<img src="/images/two-robot.png" width="103" height="85" alt="robot">
					</a>
					<div class="footer-robot-dilog">
						<div class="inner-robot-dilog">
							Do you have a question? <script type="text/javascript">/*<![CDATA[*/var a=new Array(".nl","bots","do","@","fo","in");document.write("<a href='mailto:");for(i=a.length-1;i>=0;i--){document.write(a[i])}document.write("?subject=DoBots Contact' class='btn btn-default'>Yes</a>");/*]]>*/</script>
							<div class="inner-arrow-right">
								<img alt="dilog" class="img-responsive" src="/images/inner-dilog.png" draggable="false"> </div>
						</div>

					</div>
					</li>
				</ul>

			</div>
		</div>
	</div>
</footer>




  <script type="text/javascript">
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-17146802-10', 'auto');
ga('send', 'pageview');
</script>
<script type="text/javascript" async src="https://www.google-analytics.com/analytics.js"></script>






<!-- in debug mode, Google Chrome worries about .map files, do not worry -->


<script type="text/javascript" src="/assets/jquery.min-7f30f220312176c728c3bb41a567ccc2e1ce2e7a8dd7c9cefd59fe197ba047b2.js"></script>

<!-- Latest compiled and minified JavaScript -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script type="text/javascript" src="/assets/jquery.flexslider-122776e067a7b77f685ce8fbbd3cb75136ce8ca23f243a50de28c1545ec6bb68.js"></script>

<script type="text/javascript" async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/javascript">
$(window).load(function(){
		$('.text-slider').flexslider({
			animation: "slide",
			start: function(slider){
				$('body').removeClass('loading');
			}
		});
	});
</script>

</div>
</body>
</html>
